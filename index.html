<!DOCTYPE html>
<html>
    <header>
        <title>ONNX Runtime JavaScript examples: Quick Start - Web (using script tag)</title>
    </header>
    <body>
        <h1>Example</h1>
        <div>
            <input title= "Image from File" type="file" id="file-in" name="file-in">
        </div>
        <h3>Image from file</h3>
        <div>
            <img id="original-image" src="#" />
        </div>
        <h3>Image from tensor resized</h3>
        <canvas id="canvasHTMLElementResize"></canvas>
        <script>
            var canvasResize = document.getElementById('canvasHTMLElementResize');
        
            async function handleImage(img) {
                // HTML Element --> Tensor + resized
                const resizedTensor = await ort.Tensor.fromImage(img, options = {resizedWidth: 1280, resizedHeight: 960});
                // Tensor --> ImageData (resized)
                const resizeImage = resizedTensor.toImageData();
            
                // Presenting the image on dom
                canvasResize.width = resizeImage.width;
                canvasResize.height = resizeImage.height;
                context = canvasResize.getContext('2d');
                context.putImageData(resizeImage, 0, 0);

                // we resize the tensor from format expected for dom render to format for onnx model, a 3 channel image
                const resizedTensor3Channel = fourChannelToThreeChannelTensor(resizedTensor)

                // use an async context to call onnxruntime functions.
                async function main(resizedTensor3Channel) {
                    try {
                        // create a new session and load the specific model.
                        // https://github.com/microsoft/onnxruntime-inference-examples/tree/main/js/api-usage_session-options
                        const sessionOption = { executionProviders: ['cpu'] };
                        const session = await ort.InferenceSession.create('./md_v5a.0.0.960.1280.onnx', sessionOption);

                        // prepare feeds. use model input names as keys. can have multiple...
                        const feeds = await {"images": resizedTensor3Channel};

                        // feed inputs and run
                        assert(feeds['images'].data.length == feeds['images'].dims[1] * feeds['images'].dims[2] * feeds['images'].dims[3]);
                        const results = await session.run(feeds);

                        // read from results
                        const dataC = results.c.data;
                        document.write(`data of result tensor 'c': ${dataC}`);

                    } catch (e) {
                        document.write(`failed to inference ONNX model: ${e}.\n`);
                    }
                }

                // call the main function and pass the resizedTensor as a parameter
                main(resizedTensor3Channel);
            }
        
            function loadImage(fileReader) {
                var img = document.getElementById("original-image");
                img.onload = () => handleImage(img);
                img.src = fileReader.result;
            }
        
            function main() {
                var img = document.getElementById("original-image");
                document.getElementById("file-in").onchange = function (evt) {
                    let target = evt.target || window.event.src, files = target.files;
                    if (FileReader && files && files.length) {
                        var fileReader = new FileReader();
                        fileReader.onload = () => loadImage(fileReader);
                        fileReader.readAsDataURL(files[0]);
                    }
                };
            }

            function fourChannelToThreeChannelTensor(tensor, dims) {
                // 1. Get buffer data from image and create R, G, and B arrays.
                var imageBufferData = tensor.data;
                const [redArray, greenArray, blueArray] = new Array(new Array(), new Array(), new Array());

                // 2. Loop through the image buffer and extract the R, G, and B channels
                for (let i = 0; i < imageBufferData.length; i += 4) {
                    redArray.push(imageBufferData[i]);
                    greenArray.push(imageBufferData[i + 1]);
                    blueArray.push(imageBufferData[i + 2]);
                    // skip data[i + 3] to filter out the alpha channel
                }

                // 3. Concatenate RGB to transpose [224, 224, 3] -> [3, 224, 224] to a number array
                const transposedData = redArray.concat(greenArray).concat(blueArray);

                // 4. convert to float32
                let i, l = transposedData.length; // length, we need this for the loop
                // create the Float32Array size 3 * 224 * 224 for these dimensions output
                const float32Data = new Float32Array(3 * tensor.dims[2] * tensor.dims[3]);
                for (i = 0; i < l; i++) {
                    float32Data[i] = transposedData[i] / 255.0; // convert to float
                }
                // 5. create the tensor object from onnxruntime-web.
                const inputTensor = new ort.Tensor("float32", float32Data, [1, 3, tensor.dims[2], tensor.dims[3]]);
                return inputTensor;
                }
            function assert(condition, message) {
                if (!condition) {
                    throw new Error(message || "Assertion failed");
                }
            }
        
            main();
        
        </script>
        <!-- import ONNXRuntime Web from CDN -->
        <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    </body>
</html>